<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Python-迴歸分析 | LION OR CAT</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="相關係數,線性迴歸, statsmodels, sklearn, itertools">
<meta name="keywords" content="線性迴歸,羅吉斯迴歸,相關係數,statsmodels,sklearn,itertools">
<meta property="og:type" content="article">
<meta property="og:title" content="Python-迴歸分析">
<meta property="og:url" content="https://ccliao.github.io/2017/06/18/python-regression/index.html">
<meta property="og:site_name" content="LION OR CAT">
<meta property="og:description" content="相關係數,線性迴歸, statsmodels, sklearn, itertools">
<meta property="og:image" content="https://ccliao.github.io/images/scatter.png">
<meta property="og:image" content="https://ccliao.github.io/images/olsr.png">
<meta property="og:image" content="https://ccliao.github.io/images/decisiontree_group.png">
<meta property="og:image" content="https://ccliao.github.io/images/svm.png">
<meta property="og:image" content="https://ccliao.github.io/images/logistic_regression.png">
<meta property="og:image" content="https://ccliao.github.io/images/randomforest.png">
<meta property="og:image" content="https://ccliao.github.io/images/customerchurn.png">
<meta property="og:updated_time" content="2017-06-24T11:02:51.335Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python-迴歸分析">
<meta name="twitter:description" content="相關係數,線性迴歸, statsmodels, sklearn, itertools">
<meta name="twitter:image" content="https://ccliao.github.io/images/scatter.png">
  
    <link rel="alternate" href="/atom.xml" title="LION OR CAT" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">LION OR CAT</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜尋"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://ccliao.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-python-regression" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/06/18/python-regression/" class="article-date">
  <time datetime="2017-06-18T04:34:06.000Z" itemprop="datePublished">2017-06-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Python/">Python</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Python-迴歸分析
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<p>相關係數,線性迴歸, statsmodels, sklearn, itertools</p>
<h2 id=""><a href="#" class="headerlink" title=""></a><a id="more"></a></h2><h2 id="相關係數"><a href="#相關係數" class="headerlink" title="相關係數"></a>相關係數</h2><p><code>rets.corr()</code></p>
<table>
<thead>
<tr>
<th></th>
<th style="text-align:right">Ctrip</th>
<th style="text-align:right">Lion</th>
</tr>
</thead>
<tbody>
<tr>
<td> Ctrip</td>
<td style="text-align:right">1.000000</td>
<td style="text-align:right">0.059657</td>
</tr>
<tr>
<td> Lion</td>
<td style="text-align:right">0.059657</td>
<td style="text-align:right">1.000000</td>
</tr>
</tbody>
</table>
<h2 id="簡單線性迴歸-LinearRegression"><a href="#簡單線性迴歸-LinearRegression" class="headerlink" title="簡單線性迴歸(LinearRegression)"></a>簡單線性迴歸(<a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html" target="_blank" rel="external">LinearRegression</a>)</h2><hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line">X1 = X.iloc[<span class="number">0</span>:len(X)].to_frame() <span class="comment">#Convert Series to DataFrame</span></div><div class="line">Y1 = Y.iloc[<span class="number">0</span>:len(Y)].to_frame()</div><div class="line">regr = LinearRegression()</div><div class="line">regr.fit(X1,Y1)</div><div class="line">regr.coef_ <span class="comment">#係數</span></div><div class="line">regr.intercept_ <span class="comment">#截距</span></div><div class="line">regr.predict(X1) <span class="comment">#依線性迴歸公式計算Y值</span></div><div class="line">% pylab inline <span class="comment">#繪製散佈圖</span></div><div class="line">plt.scatter(X1,Y1, color=<span class="string">"black"</span>)</div><div class="line">plt.xlabel(<span class="string">'戶數'</span>,fontproperties=<span class="string">'SimHei'</span>)</div><div class="line">plt.ylabel(<span class="string">'人口數'</span>,fontproperties=<span class="string">'SimHei'</span>)</div></pre></td></tr></table></figure>
<p>$$ Y = \beta_0+\beta_1X $$<br><img src="/images/scatter.png" alt="戶數與人口散佈圖"></p>
<p>錯誤訊息：<br>執行regr.fit時，產生異常訊息<br><code>Found input variables with inconsistent numbers of samples: [1, 368]</code><br>處理方式：<br>錯誤原因是sklearn要求使用DataFrame，但原資料為Series，所以將資料重新reshape即可使用X.iloc[0:len(X)].to_frame()</p>
<ul>
<li>series 是一維的數據類型，dataframe 是一個二維的、表格型的數據結構。</li>
</ul>
<h2 id="多變量線性迴歸"><a href="#多變量線性迴歸" class="headerlink" title="多變量線性迴歸"></a>多變量線性迴歸</h2><p>`線性迴歸也被稱為最小二乘法回歸（Linear Regression, also called Ordinary Least-Squares (OLS) Regression）</p>
<h2 id="sklearn"><a href="#sklearn" class="headerlink" title="sklearn"></a>sklearn</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">house = pd.read_csv(<span class="string">'python_for_data_science-master/Data/house-prices.csv'</span>)</div><div class="line">house1 = pd.concat([house,pd.get_dummies(house[<span class="string">'Brick'</span>]),pd.get_dummies(house[<span class="string">'Neighborhood'</span>])],axis=<span class="number">1</span>)</div><div class="line"><span class="keyword">del</span> house1[<span class="string">'Home'</span>], house1[<span class="string">'No'</span>], house1[<span class="string">'Brick'</span>], house1[<span class="string">'Neighborhood'</span>]</div><div class="line">X = house1[[<span class="string">'SqFt'</span>, <span class="string">'Bedrooms'</span>, <span class="string">'Bathrooms'</span>, <span class="string">'Offers'</span>, <span class="string">'Yes'</span>, <span class="string">'East'</span>, <span class="string">'North'</span>, <span class="string">'West'</span>]]</div><div class="line">Y = house1[<span class="string">'Price'</span>].values</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line">regr = LinearRegression()</div><div class="line">regr.fit(X,Y)</div><div class="line">house1[<span class="string">'Price_Predict'</span>] = regr.predict(X).astype(int)</div><div class="line">house1.head()</div></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th></th>
<th>Price</th>
<th>SqFt</th>
<th>Bedrooms</th>
<th>Bathrooms</th>
<th>Offers</th>
<th>Yes</th>
<th>East</th>
<th>North</th>
<th>West</th>
<th>Price_Predict</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>114300</td>
<td>1790</td>
<td>2</td>
<td>2</td>
<td>2</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>103182</td>
</tr>
<tr>
<td>1</td>
<td>114200</td>
<td>2030</td>
<td>4</td>
<td>2</td>
<td>3</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>116127</td>
</tr>
<tr>
<td>2</td>
<td>114800</td>
<td>1740</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>113047</td>
</tr>
<tr>
<td>3</td>
<td>94700</td>
<td>1980</td>
<td>3</td>
<td>2</td>
<td>3</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>109230</td>
</tr>
<tr>
<td>4</td>
<td>119800</td>
<td>2130</td>
<td>3</td>
<td>3</td>
<td>3</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>125063</td>
</tr>
</tbody>
</table>
<h2 id="statsmodels"><a href="#statsmodels" class="headerlink" title="statsmodels"></a>statsmodels</h2><p>參數估計：<br>矩估計（Method of Moment、MOM）<br>最小平方法（Ordinary Least Square Estimation, OLSE）<br>最大似然估計（Maximum Likelihood Estimation, MLE）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</div><div class="line">X2 = sm.add_constant(X) <span class="comment">#為模型增加常數項，即迴歸線在y軸上的截距</span></div><div class="line">est = sm.OLS(Y, X2)</div><div class="line">est2 = est.fit()</div><div class="line"><span class="keyword">print</span> (est2.summary())</div></pre></td></tr></table></figure>
<p><img src="/images/olsr.png" alt=""></p>
<ul>
<li>sklearn,statsmodels計算之結果是相同的</li>
</ul>
<p><code>regr.coef_</code><br>array([    52.99374081,   4246.79389165,   7883.27849293,  -8267.48831831,<br>        17297.34952752, -22241.61647014, -20681.03735068])</p>
<p><code>regr.intercept_</code><br>22840.535538009528</p>
<p><code>est2.params</code><br>const        22840.535538<br>SqFt            52.993741<br>Bedrooms      4246.793892<br>Bathrooms     7883.278493<br>Offers       -8267.488318<br>Yes          17297.349528<br>East        -22241.616470<br>North       -20681.037351<br>dtype: float64</p>
<ul>
<li><p>赤池信息準則 AIC (Akaike Information Criterion) 評估統計模型的複雜度和衡量統計模型「擬合」資料之優良性的一種標準，尋找可以最好地解釋數據但包含最少自由參數的模型，優先考慮的模型應是AIC值最小的那一個<br>$$ AIC = 2K - 2\ln(L) $$<br>K是參數的數量，L是似然函數<br>當模型複雜度提高（k增大）時，似然函數L也會增大，從而使AIC變小，但是k過大時，似然函數增速減緩，導致AIC增大，模型過於複雜容易造成過擬合現象。</p>
</li>
<li><p>貝葉斯信息準則 SIC (Schwartz Information Criterion)</p>
</li>
</ul>
<h2 id="itertools應用"><a href="#itertools應用" class="headerlink" title="itertools應用"></a>itertools應用</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">predictorcols = [&apos;SqFt&apos;, &apos;Bedrooms&apos;, &apos;Bathrooms&apos;, &apos;Offers&apos;, &apos;Yes&apos;, &apos;East&apos;, &apos;North&apos;]</div><div class="line">import itertools</div><div class="line">AICs = &#123;&#125;</div><div class="line">for k in range(1,len(predictorcols)+1):</div><div class="line">    for variables in itertools.combinations(predictorcols, k): </div><div class="line">        predictors  = X[list(variables)]</div><div class="line">        predictors2 = sm.add_constant(predictors)</div><div class="line">        est = sm.OLS(Y, predictors2)</div><div class="line">        res = est.fit()</div><div class="line">        AICs[variables] = res.aic</div><div class="line">from collections import Counter</div><div class="line">c = Counter(AICs)</div><div class="line">c.most_common()[::-10] #x[startAt:endBefore:skip]</div></pre></td></tr></table></figure>
<ul>
<li>itertools迭代指重覆取值，重覆反饋過程的活動<br><code>itertools.combinations([&#39;A&#39;,&#39;B&#39;,&#39;C&#39;,&#39;D&#39;],2)</code>可以得到AB,AC,AD,BC,BD,CD</li>
</ul>
<h2 id="羅吉斯迴歸-Logistic-Regression"><a href="#羅吉斯迴歸-Logistic-Regression" class="headerlink" title="羅吉斯迴歸 (Logistic Regression)"></a>羅吉斯迴歸 (<a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" target="_blank" rel="external">Logistic Regression</a>)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">============== ==== ==== ======= ===== ====================</div><div class="line">                Min  Max   Mean    SD   Class Correlation</div><div class="line">============== ==== ==== ======= ===== ====================</div><div class="line">sepal length:   4.3  7.9   5.84   0.83    0.7826</div><div class="line">sepal width:    2.0  4.4   3.05   0.43   -0.4194</div><div class="line">petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)</div><div class="line">petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)</div><div class="line">============== ==== ==== ======= ===== ====================</div></pre></td></tr></table></figure>
<p>上述為iris資料庫之描述性統計資料，下面取petal length及petal width使用，分別取最小值及最大值後加減1，並進行meshgrid處理<br>(0, 7.9, 0.1)<br>(-0.9, 3.5, 0.1) –&gt; 44個區間(-0.9, -0.8, -0.7,…..3.4)<br>XX即為[ 0. ,  0.1,  0.2, ….  7.6, 7.7,  7.8]共44個<br>yy即為[-0.9, -0.9, -0.9, …. -0.9, -0.9, -0.9][-0.8, -0.8, -0.8, …. -0.8, -0.8, -0.8]…..[3.4, 3.4, 3.4, …. 3.4, 3.4, 3.4]<br>Z即為依據xx,yy資料產出之決策樹預測結果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</div><div class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</div><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</div><div class="line"></div><div class="line"><span class="comment">#圖形中文顯示處理</span></div><div class="line">matplotlib.rc(<span class="string">'font'</span>, **&#123;<span class="string">'sans-serif'</span> : <span class="string">'SimHei'</span>,</div><div class="line">                       <span class="string">'family'</span> : <span class="string">'sans-serif'</span>&#125;)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_estimator</span><span class="params">(estimator, X, y, title)</span>:</span></div><div class="line">    x_min, x_max = X[:, <span class="number">0</span>].min() - <span class="number">1</span>, X[:, <span class="number">0</span>].max() + <span class="number">1</span> <span class="comment">##加1減1只是為了繪圖時留空白</span></div><div class="line">    y_min, y_max = X[:, <span class="number">1</span>].min() - <span class="number">1</span>, X[:, <span class="number">1</span>].max() + <span class="number">1</span></div><div class="line">    xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class="number">0.1</span>),</div><div class="line">                         np.arange(y_min, y_max, <span class="number">0.1</span>)) <span class="comment">#meshgrid根據坐標向量創建坐標矩陣</span></div><div class="line">    Z = estimator.predict(np.c_[xx.ravel(), yy.ravel()]) <span class="comment">#一維,共3476筆資料</span></div><div class="line">    <span class="comment">#ravel() Return a contiguous flattened array</span></div><div class="line">	<span class="comment">#np.c_ 串接兩個list,np.ravel將矩陣變為一維</span></div><div class="line">	Z = Z.reshape(xx.shape) <span class="comment">#二維,共44筆資料(44,79)</span></div><div class="line">    plt.plot()</div><div class="line">	<span class="comment">#Contours(輪廓) can be explained simply as a curve joining all the continuous points (along the boundary), having same color or intensity.</span></div><div class="line">    plt.contourf(xx, yy, Z, alpha=<span class="number">0.4</span>, cmap = plt.cm.RdYlBu) <span class="comment">#cmap- Colormap #alpha透明度,愈小愈透明0~1</span></div><div class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y,  cmap = plt.cm.brg) <span class="comment">#c - color</span></div><div class="line">    plt.title(title)</div><div class="line">    plt.xlabel(<span class="string">'Petal.Length'</span>)</div><div class="line">    plt.ylabel(<span class="string">'Petal.Width'</span>)</div><div class="line">    plt.show()</div><div class="line"></div><div class="line">iris = load_iris()</div><div class="line">X = iris.data[:,[<span class="number">2</span>,<span class="number">3</span>]]</div><div class="line">y = iris.target[:]</div><div class="line"><span class="comment">#決策樹DecisionTree</span></div><div class="line">clf = tree.DecisionTreeClassifier()</div><div class="line">clf.fit(X, y)</div><div class="line"><span class="comment">#支援向量機SVM</span></div><div class="line">clf1 = SVC(kernel=<span class="string">"linear"</span>)</div><div class="line">clf1.fit(X, y)</div><div class="line"><span class="comment">#羅吉斯迴歸</span></div><div class="line">clf2 = LogisticRegression()</div><div class="line">clf2.fit(X, y)</div><div class="line"><span class="comment">#隨機森林</span></div><div class="line">clf3 = RandomForestClassifier(n_estimators=<span class="number">100</span>, criterion=<span class="string">"entropy"</span>, random_state=<span class="number">0</span>)</div><div class="line">clf3.fit(X, y)</div><div class="line"></div><div class="line">plot_estimator(clf, X, y, <span class="string">"決策樹"</span>)</div><div class="line">plot_estimator(clf1, X, y, <span class="string">"支援向量機"</span>)</div><div class="line">plot_estimator(clf2, X, y, <span class="string">"羅吉斯迴歸"</span>)</div><div class="line">plot_estimator(clf3, X, y, <span class="string">"隨機森林"</span>)</div></pre></td></tr></table></figure>
<p><img src="/images/decisiontree_group.png" alt="決策樹模型"><br><img src="/images/svm.png" alt="支援向量機模型"><br><img src="/images/logistic_regression.png" alt="羅吉斯迴歸模型"><br><img src="/images/randomforest.png" alt="隨機森林模型"></p>
<p>The C parameter tells the SVM optimization how much you want to avoid misclassifying each training example. For large values of C, the optimization will choose a smaller-margin hyperplane if that hyperplane does a better job of getting all the training points classified correctly. Conversely, a very small value of C will cause the optimizer to look for a larger-margin separating hyperplane, even if that hyperplane misclassifies more points. For very tiny values of C, you should get misclassified examples, often even if your training data is linearly separable.</p>
<p>傳統線性迴歸的迴歸係數（regression coefficient）的解釋為「當自變項增加一個單位，依變項則會增加多少單位」，但是在Logistic regression的迴歸係數解釋為「當自變項增加一個單位，依變項1相對依變項0的機率會增加幾倍」，也就是說「自變項增加一個單位，依變項有發生狀況（習慣稱為Event）相對於沒有發生狀況（non-event）的比值」，這個比值就是勝算比（Odds ratio, OR）。我們可以這樣說，除了迴歸係數的解釋方法不太相同之外，基本上可說傳統線性迴歸跟Logistic regression是一樣的分析。<br>from <a href="http://dasanlin888.pixnet.net/blog/post/34468457-logistic-regression%E4%BB%8B%E7%B4%B9---%E6%99%A8%E6%99%B0%E7%B5%B1%E8%A8%88%E6%9E%97%E6%98%9F%E5%B8%86%E9%A1%A7%E5%95%8F%E6%95%B4" target="_blank" rel="external">晨晰統計</a></p>
<h2 id="顧客忠誠度分析"><a href="#顧客忠誠度分析" class="headerlink" title="顧客忠誠度分析"></a>顧客忠誠度分析</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">	state	account_length	area_code	international_plan	voice_mail_plan	number_vmail_messages	total_day_minutes	total_day_calls	total_day_charge	total_eve_minutes	total_eve_calls	total_eve_charge	total_night_minutes	total_night_calls	total_night_charge	total_intl_minutes	total_intl_calls	total_intl_charge	number_customer_service_calls	churn</div><div class="line">1	KS	128	area_code_415	no	yes	25	265.1	110	45.07	197.4	99	16.78	244.7	91	11.01	10.0	3	2.70	1	no</div><div class="line">2	OH	107	area_code_415	no	yes	26	161.6	123	27.47	195.5	103	16.62	254.4	103	11.45	13.7	3	3.70	1	no</div><div class="line">3	NJ	137	area_code_415	no	no	0	243.4	114	41.38	121.2	110	10.30	162.6	104	7.32	12.2	5	3.29	0	no</div><div class="line">4	OH	84	area_code_408	yes	no	0	299.4	71	50.90	61.9	88	5.26	196.9	89	8.86	6.6	7	1.78	2	no</div><div class="line">5	OK	75	area_code_415	yes	no	0	166.7	113	28.34	148.3	122	12.61	186.9	121	8.41	10.1	3	2.73	3	no</div></pre></td></tr></table></figure>
<p>電信公司之客戶忠誠度分析資料</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas</div><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</div><div class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> export_graphviz</div><div class="line"><span class="keyword">import</span> graphviz</div><div class="line"><span class="keyword">import</span> pydotplus</div><div class="line"><span class="comment">#讀入資料</span></div><div class="line">df = pandas.read_csv(<span class="string">'python_for_data_science-master/Data/customer_churn.csv'</span>, index_col=<span class="number">0</span>, header = <span class="number">0</span>)</div><div class="line">df = df.iloc[:,<span class="number">3</span>:]</div><div class="line"><span class="comment">#將yes/no資料轉換為1/0</span></div><div class="line">cat_var = [<span class="string">'international_plan'</span>,<span class="string">'voice_mail_plan'</span>, <span class="string">'churn'</span>]</div><div class="line"><span class="keyword">for</span> cat <span class="keyword">in</span> cat_var:</div><div class="line">    df[cat] = df[cat].map(<span class="keyword">lambda</span> e: <span class="number">1</span> <span class="keyword">if</span> e == <span class="string">'yes'</span> <span class="keyword">else</span> <span class="number">0</span>)</div><div class="line"><span class="comment">#將churn欄位歸為y,其餘欄位為X</span></div><div class="line">y = df.iloc[:,<span class="number">-1</span>]</div><div class="line">X = df.iloc[:,:<span class="number">-1</span>]</div><div class="line"></div><div class="line"><span class="comment">#使用決策樹分析</span></div><div class="line">dt = tree.DecisionTreeClassifier(max_depth=<span class="number">3</span>)</div><div class="line">dt.fit(X, y)</div><div class="line"><span class="comment">#計算準確率</span></div><div class="line"><span class="keyword">print</span> (numpy.sum(y== dt.predict(X)) / len(y))</div><div class="line"><span class="comment"># 繪製決策樹圖</span></div><div class="line">dot_data = tree.export_graphviz(dt, out_file=<span class="keyword">None</span>, </div><div class="line">                     filled=<span class="keyword">True</span>, rounded=<span class="keyword">True</span>,  </div><div class="line">                     special_characters=<span class="keyword">True</span>)  </div><div class="line">graph = pydotplus.graph_from_dot_data(dot_data)  </div><div class="line">Image(graph.create_png())</div></pre></td></tr></table></figure>
<p><img src="/images/customerchurn.png" alt="顧客忠誠度分析"></p>
<p>正確率的計算方法有二<br>1.使用from sklearn.metrics import accuracy_score套件 <code>accuracy_score(iris.target, predicted)</code><br>2.直接sum()計算　<code>numpy.sum(y== dt.predict(X)) / len(y)</code></p>
<p><strong>混洧矩陣</strong><br><code>from sklearn.metrics import confusion_matrix</code><br><code>confusion_matrix(iris.target, predicted)</code></p>
<p>不同的正確率計算方式<br><code>from sklearn.metrics import classification_report</code><br><code>print(classification_report(iris.target, predicted))</code></p>
<pre><code>  | precision  |  recall  | f1-score   | support

0  |     1.00   |   1.00    |  1.00       | 50
1  |     0.98   |   0.90    |  0.94       | 50
2  |     0.91   |   0.98    |  0.94       | 50
</code></pre><p>avg / total  |     0.96   |   0.96    |  0.96      | 150</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://ccliao.github.io/2017/06/18/python-regression/" data-id="cj4b3ovfa000mlob2lsq3mp3i" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/itertools/">itertools</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/sklearn/">sklearn</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/statsmodels/">statsmodels</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/相關係數/">相關係數</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/線性迴歸/">線性迴歸</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/羅吉斯迴歸/">羅吉斯迴歸</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/06/18/python-drawing/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Python-繪圖語法
        
      </div>
    </a>
  
  
    <a href="/2017/06/18/python-pandas/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Python-Pandas語法</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/06/24/python-mlp/">Python-mlp</a>
          </li>
        
          <li>
            <a href="/2017/06/24/python-svm/">Python-支援向量機SVM</a>
          </li>
        
          <li>
            <a href="/2017/06/22/python-numpy/">python-numpy</a>
          </li>
        
          <li>
            <a href="/2017/06/20/python-decisiontree/">Python-決策樹</a>
          </li>
        
          <li>
            <a href="/2017/06/18/markdown-doc/">MarkDown使用</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分類</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/MarkDown/">MarkDown</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/QGIS/">QGIS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">標籤</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/MLP/">MLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Neural-Network/">Neural Network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/One-Hot/">One-Hot</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/">SVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/contourf/">contourf</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/graphviz/">graphviz</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/itertools/">itertools</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/matplotlib/">matplotlib</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/meshgrid/">meshgrid</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/numpy/">numpy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pydotplus/">pydotplus</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sklearn/">sklearn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/statsmodels/">statsmodels</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/支援向量機/">支援向量機</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/決策樹/">決策樹</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬蟲/">爬蟲</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/相關係數/">相關係數</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/經緯度/">經緯度</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/線性迴歸/">線性迴歸</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/繪圖/">繪圖</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/羅吉斯迴歸/">羅吉斯迴歸</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">標籤雲</h3>
    <div class="widget tagcloud">
      <a href="/tags/MLP/" style="font-size: 10px;">MLP</a> <a href="/tags/Neural-Network/" style="font-size: 10px;">Neural Network</a> <a href="/tags/One-Hot/" style="font-size: 10px;">One-Hot</a> <a href="/tags/SVM/" style="font-size: 10px;">SVM</a> <a href="/tags/contourf/" style="font-size: 10px;">contourf</a> <a href="/tags/graphviz/" style="font-size: 10px;">graphviz</a> <a href="/tags/itertools/" style="font-size: 10px;">itertools</a> <a href="/tags/matplotlib/" style="font-size: 10px;">matplotlib</a> <a href="/tags/meshgrid/" style="font-size: 10px;">meshgrid</a> <a href="/tags/numpy/" style="font-size: 10px;">numpy</a> <a href="/tags/pydotplus/" style="font-size: 10px;">pydotplus</a> <a href="/tags/sklearn/" style="font-size: 10px;">sklearn</a> <a href="/tags/statsmodels/" style="font-size: 10px;">statsmodels</a> <a href="/tags/支援向量機/" style="font-size: 10px;">支援向量機</a> <a href="/tags/決策樹/" style="font-size: 10px;">決策樹</a> <a href="/tags/爬蟲/" style="font-size: 10px;">爬蟲</a> <a href="/tags/相關係數/" style="font-size: 10px;">相關係數</a> <a href="/tags/經緯度/" style="font-size: 10px;">經緯度</a> <a href="/tags/線性迴歸/" style="font-size: 10px;">線性迴歸</a> <a href="/tags/繪圖/" style="font-size: 10px;">繪圖</a> <a href="/tags/羅吉斯迴歸/" style="font-size: 10px;">羅吉斯迴歸</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">彙整</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">六月 2017</a></li></ul>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Kevin Liao<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>